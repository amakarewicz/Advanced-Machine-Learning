{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "889107a6",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "*El≈ºbieta Jowik* <br>\n",
    "*Agata Makarewicz*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4542708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "plt.rcParams['figure.figsize'] = (9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd65462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def evaluate_classification(true, pred):\n",
    "    Accuracy = accuracy_score(true, pred)\n",
    "    Precision = precision_score(true, pred)\n",
    "    Recall = recall_score(true, pred)\n",
    "    F1_score = f1_score(true, pred)\n",
    "    \n",
    "    results = pd.DataFrame(np.array([Accuracy, Precision, Recall, F1_score]))\n",
    "    results.index = ['Accuracy', 'Precision', 'Recall', 'F1_score']\n",
    "    return results\n",
    "\n",
    "# target_names = list(np.unique(data_target))\n",
    "\n",
    "# def evaluate_metrics(true, pred):\n",
    "#     Precision = precision_score(true, pred, average = None)\n",
    "#     Recall = recall_score(true, pred, average = None)\n",
    "#     F1_score = f1_score(true, pred, average = None)\n",
    "#     F_beta = fbeta_score(true, pred, average = None,beta=2)\n",
    "    \n",
    "#     results = pd.DataFrame(np.array([Precision,Recall,F1_score,F_beta]))\n",
    "#     results.index = ['Precision','Recall','F1_score','F_beta']\n",
    "#     results.columns = target_names\n",
    "#     f1 = f1_score(true, pred, average='weighted')\n",
    "#     return results, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef7326cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading preprocessed datasets\n",
    "data_adult_train = pd.read_csv('datasets/project1/preprocessed/adult_train_x.csv')\n",
    "data_adult_test = pd.read_csv('datasets/project1/preprocessed/adult_test_x.csv')\n",
    "\n",
    "data_credit_train = pd.read_csv('datasets/project1/preprocessed/credit_train_x.csv')\n",
    "data_credit_test = pd.read_csv('datasets/project1/preprocessed/credit_test_x.csv')\n",
    "\n",
    "data_sick_train = pd.read_csv('datasets/project1/preprocessed/sick_train_x.csv')\n",
    "data_sick_test = pd.read_csv('datasets/project1/preprocessed/sick_test_x.csv')\n",
    "\n",
    "data_titanic_train = pd.read_csv('datasets/project1/preprocessed/titanic_train_x.csv')\n",
    "data_titanic_test = pd.read_csv('datasets/project1/preprocessed/titanic_test_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf15acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading preprocessed datasets\n",
    "target_adult_train = pd.read_csv('datasets/project1/preprocessed/adult_train_y.csv')\n",
    "target_adult_test = pd.read_csv('datasets/project1/preprocessed/adult_test_y.csv')\n",
    "\n",
    "target_credit_train = pd.read_csv('datasets/project1/preprocessed/credit_train_y.csv')\n",
    "target_credit_test = pd.read_csv('datasets/project1/preprocessed/credit_test_y.csv')\n",
    "\n",
    "target_sick_train = pd.read_csv('datasets/project1/preprocessed/sick_train_y.csv')\n",
    "target_sick_test = pd.read_csv('datasets/project1/preprocessed/sick_test_y.csv')\n",
    "\n",
    "target_titanic_train = pd.read_csv('datasets/project1/preprocessed/titanic_train_y.csv')\n",
    "target_titanic_test = pd.read_csv('datasets/project1/preprocessed/titanic_test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f02cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(true, pred):\n",
    "    correct = 0\n",
    "    for i in range(len(true)):\n",
    "        if true[i] == pred[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(true))\n",
    "\n",
    "# def precision_metric(true, pred):\n",
    "    \n",
    "# def recall_metric(true, pred):\n",
    "\n",
    "# def f_metric(true, pred):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a758237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   LINKI !!!   #################################################\n",
    "# https://github.com/pysal/spglm\n",
    "# https://dphi.tech/blog/tutorial-on-logistic-regression-using-python/\n",
    "# https://github.com/PhongHoangg/Gradient-Descent-for-Logistics-Regression/blob/main/Gradient%20Descent%20for%20Logistics%20Regression.ipynb\n",
    "# https://machinelearningmastery.com/implement-logistic-regression-stochastic-gradient-descent-scratch-python/\n",
    "# https://www.analyticsvidhya.com/blog/2021/05/how-can-we-implement-logistic-regression/\n",
    "# https://towardsdatascience.com/building-a-logistic-regression-in-python-301d27367c24\n",
    "# https://github.com/theroyakash/Adam/blob/master/Code/Adam.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11bb7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def iwls_optimizer():\n",
    "\n",
    "# def gd_optimizer():\n",
    "    \n",
    "# def sgd_optimizer():\n",
    "    \n",
    "# def adam_optimizer():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b61ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate logistic regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = predict(row, coef)\n",
    "            error = row[-1] - yhat\n",
    "            sum_error += error**2\n",
    "            coef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return coef\n",
    "\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    coef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "    for row in test:\n",
    "        yhat = predict(row, coef)\n",
    "        yhat = round(yhat)\n",
    "        predictions.append(yhat)\n",
    "    return(predictions)\n",
    "\n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0]\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coefficients[i + 1] * row[i]\n",
    "    return 1.0 / (1.0 + exp(-yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6193b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/implement-logistic-regression-stochastic-gradient-descent-scratch-python/\n",
    "\n",
    "# Logistic Regression on Diabetes Dataset\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import exp\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tfor i in range(len(dataset[0])):\n",
    "\t\tcol_values = [row[i] for row in dataset]\n",
    "\t\tvalue_min = min(col_values)\n",
    "\t\tvalue_max = max(col_values)\n",
    "\t\tminmax.append([value_min, value_max])\n",
    "\treturn minmax\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)):\n",
    "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    "\n",
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "\tyhat = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tyhat += coefficients[i + 1] * row[i]\n",
    "\treturn 1.0 / (1.0 + exp(-yhat))\n",
    "\n",
    "# Estimate logistic regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tfor row in train:\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "\t\t\terror = row[-1] - yhat\n",
    "\t\t\tcoef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "\treturn coef\n",
    "\n",
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "\tfor row in test:\n",
    "\t\tyhat = predict(row, coef)\n",
    "\t\tyhat = round(yhat)\n",
    "\t\tpredictions.append(yhat)\n",
    "\treturn(predictions)\n",
    "\n",
    "# Test the logistic regression algorithm on the diabetes dataset\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'pima-indians-diabetes.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 100\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
