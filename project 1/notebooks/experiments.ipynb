{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147c3f02",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "*El≈ºbieta Jowik* <br>\n",
    "*Agata Makarewicz*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf101c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T06:12:28.405513Z",
     "start_time": "2022-03-30T06:12:28.393308Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "from utils import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "\n",
    "import os\n",
    "from LogisticRegression import LogisticRegression\n",
    "from ClassificationEvaluator import ClassificationEvaluator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_directory='../datasets/preprocessed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b3112",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62b256f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T06:18:21.568771Z",
     "start_time": "2022-03-30T06:18:20.431772Z"
    }
   },
   "outputs": [],
   "source": [
    "frames={}\n",
    "for filename in os.listdir(data_directory):\n",
    "    # display(Markdown(f'### {filename} data'))\n",
    "    data=pd.read_csv(f\"{data_directory}/{filename}\")\n",
    "    # display(data.head(3))\n",
    "    frames[filename.split('.')[0]]=np.array(data)\n",
    "    \n",
    "keys_lst=list(frames.keys())\n",
    "subsets_lst=[tuple(keys_lst[i:i + 4]) for i in range(0, len(keys_lst), 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3572bcc8",
   "metadata": {},
   "source": [
    "### Experiments setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ded0ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T06:18:32.931899Z",
     "start_time": "2022-03-30T06:18:32.919420Z"
    }
   },
   "outputs": [],
   "source": [
    "# default parameters\n",
    "b1=0.9\n",
    "b2=0.999\n",
    "eps=1e-8\n",
    "sample_size = 1\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dedfa2",
   "metadata": {},
   "source": [
    "### 1. Convergence analysis: how the value of log-likelihood function depends on the number of iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944bcbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience=None\n",
    "min_delta=None\n",
    "iterations = 1000 \n",
    "\n",
    "results={}\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83277db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T06:21:56.996608Z",
     "start_time": "2022-03-30T06:21:37.982030Z"
    }
   },
   "outputs": [],
   "source": [
    "for item in subsets_lst:\n",
    "        \n",
    "    X_test_key, y_test_key, X_train_key, y_train_key = item\n",
    "    X_test, y_test, X_train, y_train = frames[X_test_key], frames[y_test_key], frames[X_train_key], frames[y_train_key]\n",
    "    X_train_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "    \n",
    "    dataset_name=X_train_key.split(\"_\")[0]\n",
    "    \n",
    "    irls_kwds={\"iterations\": iterations, \"min_delta\":min_delta, \"patience\":patience}\n",
    "    gd_kwds={\"iterations\": iterations, \"alpha\": learning_rate, \"min_delta\":min_delta, \"patience\":patience}\n",
    "    sgd_kwds={\"iterations\": iterations, \"alpha\": learning_rate, \"sample_size\": sample_size,\n",
    "        \"min_delta\":min_delta,\"patience\":patience}\n",
    "    adam_kwds={\"iterations\": iterations, \"b1\": b1, \"b2\": b2, \"alpha\": learning_rate, \"epsilon\": eps,\n",
    "        \"min_delta\":min_delta, \"patience\":patience}\n",
    "    \n",
    "    if dataset_name != 'adult':\n",
    "        _,_,_,irls_cost_history=logreg.fit(X_train_b,y_train,**irls_kwds)\n",
    "    _,_,_,gd_cost_history=logreg.fit(X_train_b,y_train,**gd_kwds)\n",
    "    _,_,_,sgd_cost_history=logreg.fit(X_train_b,y_train,**sgd_kwds)\n",
    "    _,_,_,adam_cost_history=logreg.fit(X_train,y_train,**adam_kwds)\n",
    "    \n",
    "    if dataset_name != 'adult':\n",
    "        results[f\"irls_{dataset_name}\"]=irls_cost_history\n",
    "    results[f\"gd_{dataset_name}\"]=gd_cost_history\n",
    "    results[f\"sgd_{dataset_name}\"]=sgd_cost_history\n",
    "    results[f\"adam_{dataset_name}\"]=adam_cost_history\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.index.name = 'n_iter'\n",
    "results.to_csv('./../results/convergence_analysis_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9061087b",
   "metadata": {},
   "source": [
    "### 2.1 Learning rate evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3f6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=0.9\n",
    "b2=0.999\n",
    "eps=1e-8\n",
    "sample_size = 1\n",
    "learning_rate = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "\n",
    "patience=None\n",
    "min_delta=None\n",
    "iterations = 1000 \n",
    "\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd5a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in subsets_lst:\n",
    "    \n",
    "    results = {}\n",
    "    gd_evaluation_acc, sgd_evaluation_acc, adam_evaluation_acc = [], [], []\n",
    "    gd_evaluation_f1, sgd_evaluation_f1, adam_evaluation_f1 = [], [], []\n",
    "    cost_results = {}\n",
    "    gd_history, sgd_history, adam_history = [], [], []\n",
    "\n",
    "    X_test_key, y_test_key, X_train_key, y_train_key = item\n",
    "    X_test, y_test, X_train, y_train = frames[X_test_key], frames[y_test_key], frames[X_train_key], frames[y_train_key]\n",
    "    X_train_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "    y_test = [y for row in y_test for y in row]\n",
    "\n",
    "    dataset_name=X_train_key.split(\"_\")[0]\n",
    "    \n",
    "    for lr in learning_rate:\n",
    "        gd_kwds={\"iterations\": iterations, \"alpha\": lr, \"min_delta\":min_delta, \"patience\":patience}\n",
    "        sgd_kwds={\"iterations\": iterations, \"alpha\": lr, \"sample_size\": sample_size,\n",
    "            \"min_delta\":min_delta,\"patience\":patience}\n",
    "        adam_kwds={\"iterations\": iterations, \"b1\": b1, \"b2\": b2, \"alpha\": lr, \"epsilon\": eps,\n",
    "            \"min_delta\":min_delta, \"patience\":patience}\n",
    "\n",
    "        gd_params, _, _, gd_cost_history = logreg.fit(X_train_b,y_train,**gd_kwds)\n",
    "        _, gd_pred = logreg.predict(X_test_b, gd_params)\n",
    "        gd_metrics_acc = ClassificationEvaluator().accuracy(y_test,gd_pred)\n",
    "        gd_metrics_f1 = ClassificationEvaluator().f1_score(y_test,gd_pred)\n",
    "\n",
    "        sgd_params, _, _, sgd_cost_history = logreg.fit(X_train_b,y_train,**sgd_kwds)\n",
    "        _, sgd_pred = logreg.predict(X_test_b, sgd_params)\n",
    "        sgd_metrics_acc = ClassificationEvaluator().accuracy(y_test,sgd_pred)\n",
    "        sgd_metrics_f1 = ClassificationEvaluator().f1_score(y_test,sgd_pred)\n",
    "\n",
    "        adam_params, _, _, adam_cost_history = logreg.fit(X_train,y_train,**adam_kwds)\n",
    "        _, adam_pred = logreg.predict(X_test, adam_params[0], adam_params[1])\n",
    "        adam_metrics_acc = ClassificationEvaluator().accuracy(y_test,adam_pred)\n",
    "        adam_metrics_f1 = ClassificationEvaluator().f1_score(y_test,adam_pred)\n",
    "        \n",
    "        gd_evaluation_acc.append(gd_metrics_acc)\n",
    "        sgd_evaluation_acc.append(sgd_metrics_acc)\n",
    "        adam_evaluation_acc.append(adam_metrics_acc)\n",
    "\n",
    "        gd_evaluation_f1.append(gd_metrics_f1)\n",
    "        sgd_evaluation_f1.append(sgd_metrics_f1)\n",
    "        adam_evaluation_f1.append(adam_metrics_f1)\n",
    "\n",
    "        gd_history.append(gd_cost_history)\n",
    "        sgd_history.append(sgd_cost_history)\n",
    "        adam_history.append(adam_cost_history)\n",
    "\n",
    "    results_acc = pd.concat([pd.Series(gd_evaluation_acc), pd.Series(sgd_evaluation_acc), pd.Series(adam_evaluation_acc)], axis=1)\n",
    "    results_acc.columns = ['gd', 'sgd', 'adam']\n",
    "    results_acc.index = learning_rate\n",
    "    results_acc.index.name = \"Learning rate\"\n",
    "    results_acc_melted = pd.melt(results_acc.reset_index(), id_vars=['Learning rate'], value_vars=['gd', 'sgd', 'adam'])\n",
    "    results_acc_melted.columns=['Learning rate', 'Algorithm', 'Accuracy']\n",
    "\n",
    "    results_acc_melted.to_csv(f\"./../results/learning_rate_acc_{dataset_name}.csv\")\n",
    "\n",
    "    results_f1 = pd.concat([pd.Series(gd_evaluation_f1), pd.Series(sgd_evaluation_f1), pd.Series(adam_evaluation_f1)], axis=1)\n",
    "    results_f1.columns = ['gd', 'sgd', 'adam']\n",
    "    results_f1.index = learning_rate\n",
    "    results_f1.index.name = \"Learning rate\"\n",
    "    results_f1_melted = pd.melt(results_f1.reset_index(), id_vars=['Learning rate'], value_vars=['gd', 'sgd', 'adam'])\n",
    "    results_f1_melted.columns=['Learning rate', 'Algorithm', 'F1-Score']\n",
    "\n",
    "    results_f1_melted.to_csv(f\"./../results/learning_rate_f1_{dataset_name}.csv\")\n",
    "\n",
    "    cost_results = pd.concat([pd.DataFrame(gd_history).T, pd.DataFrame(sgd_history).T, pd.DataFrame(adam_history).T], axis=1)\n",
    "    columns = []\n",
    "    for alg in ['gd', 'sgd', 'adam']:\n",
    "        for l in learning_rate:\n",
    "            l_e = '{:.0e}'.format(l)\n",
    "            columns.append(alg+f\"_{l_e}\")\n",
    "    cost_results.columns = columns\n",
    "    cost_results.index.name = 'n_iter'\n",
    "    cost_results.to_csv(f'./../results/learning_rate_cost_{dataset_name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77385cc",
   "metadata": {},
   "source": [
    "### 2.2 ADAM b1/b2 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292c71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1s=[0.5, 0.6, 0.7, 0.8, 0.9, 0.999]\n",
    "b2s=[0.5, 0.6, 0.7, 0.8, 0.9, 0.999]\n",
    "eps=1e-8 \n",
    "sample_size = 1\n",
    "learning_rate = 1e-4\n",
    "\n",
    "patience=None\n",
    "min_delta=None\n",
    "iterations = 1000\n",
    "\n",
    "results=pd.DataFrame()\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "518cae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in subsets_lst:\n",
    "    \n",
    "    adam_evaluation = []\n",
    "    \n",
    "    X_test_key, y_test_key, X_train_key, y_train_key = item\n",
    "    X_test, y_test, X_train, y_train = frames[X_test_key], frames[y_test_key], frames[X_train_key], frames[y_train_key]\n",
    "    X_train_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "    y_test = [y for row in y_test for y in row]\n",
    "\n",
    "    dataset_name=X_train_key.split(\"_\")[0]\n",
    "    \n",
    "    for b1 in b1s:\n",
    "        adam_b1_evaluation = []\n",
    "        for b2 in b2s:\n",
    "            adam_kwds={\"iterations\": iterations, \"b1\": b1, \"b2\": b2, \"alpha\": lr, \"epsilon\": eps,\n",
    "            \"min_delta\":min_delta, \"patience\":patience}\n",
    "\n",
    "            adam_params, _, _, _ = logreg.fit(X_train,y_train,**adam_kwds)\n",
    "            _, adam_pred = logreg.predict(X_test, adam_params[0], adam_params[1])\n",
    "            adam_metrics = ClassificationEvaluator().accuracy(y_test,adam_pred)\n",
    "\n",
    "            adam_b1_evaluation.append(adam_metrics)\n",
    "        adam_evaluation.append(adam_b1_evaluation)\n",
    "\n",
    "    results = pd.DataFrame(adam_evaluation)\n",
    "    results.columns = b2s\n",
    "    results.index = b1s\n",
    "    results.index.name = \"b1\"\n",
    "\n",
    "    results.to_csv(f\"./../results/adam_b1_b2_{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affe844",
   "metadata": {},
   "source": [
    "### 3. Benchmark with LDA, QDA & KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f77f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=0.9\n",
    "b2=0.999\n",
    "eps=1e-8\n",
    "sample_size = 1\n",
    "learning_rate = 1e-4 \n",
    "\n",
    "patience=None \n",
    "min_delta=None \n",
    "iterations = 1000 \n",
    "\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1686250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "qda = QDA()\n",
    "knn = KNeighborsClassifier(n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c108a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in subsets_lst:\n",
    "    \n",
    "    X_test_key, y_test_key, X_train_key, y_train_key = item\n",
    "    X_test, y_test, X_train, y_train = frames[X_test_key], frames[y_test_key], frames[X_train_key], frames[y_train_key]\n",
    "    X_train_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "    y_test = [y for row in y_test for y in row]\n",
    "\n",
    "    dataset_name=X_train_key.split(\"_\")[0]\n",
    "    \n",
    "    irls_kwds={\"iterations\": iterations, \"min_delta\":min_delta, \"patience\":patience}\n",
    "    gd_kwds={\"iterations\": iterations, \"alpha\": learning_rate, \"min_delta\":min_delta, \"patience\":patience}\n",
    "    sgd_kwds={\"iterations\": iterations, \"alpha\": learning_rate, \"sample_size\": sample_size,\n",
    "        \"min_delta\":min_delta,\"patience\":patience}\n",
    "    adam_kwds={\"iterations\": iterations, \"b1\": b1, \"b2\": b2, \"alpha\": learning_rate, \"epsilon\": eps,\n",
    "        \"min_delta\":min_delta, \"patience\":patience}\n",
    "    \n",
    "    if dataset_name != 'adult':\n",
    "        irls_params, _, _, _ = logreg.fit(X_train_b,y_train,**irls_kwds)\n",
    "        _, irls_pred = logreg.predict(X_test_b, irls_params)\n",
    "        irls_metrics = ClassificationEvaluator().calculate_all(y_test,irls_pred)\n",
    "\n",
    "    gd_params, _, _, _ = logreg.fit(X_train_b,y_train,**gd_kwds)\n",
    "    _, gd_pred = logreg.predict(X_test_b, gd_params)\n",
    "    gd_metrics = ClassificationEvaluator().calculate_all(y_test,gd_pred)\n",
    "\n",
    "    sgd_params, _, _, _ = logreg.fit(X_train_b,y_train,**sgd_kwds)\n",
    "    _, sgd_pred = logreg.predict(X_test_b, sgd_params)\n",
    "    sgd_metrics = ClassificationEvaluator().calculate_all(y_test,sgd_pred)\n",
    "\n",
    "    adam_params, _, _, _ = logreg.fit(X_train,y_train,**adam_kwds)\n",
    "    _, adam_pred = logreg.predict(X_test, adam_params[0], adam_params[1])\n",
    "    adam_metrics = ClassificationEvaluator().calculate_all(y_test,adam_pred)\n",
    "\n",
    "    lda.fit(X_train, y_train)\n",
    "    lda_pred = lda.predict(X_test)\n",
    "    lda_metrics = ClassificationEvaluator().calculate_all(y_test,lda_pred)\n",
    "\n",
    "    qda.fit(X_train, y_train)\n",
    "    qda_pred = qda.predict(X_test)\n",
    "    qda_metrics = ClassificationEvaluator().calculate_all(y_test,qda_pred)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_metrics = ClassificationEvaluator().calculate_all(y_test,knn_pred)\n",
    "\n",
    "    index=['LR - IRLS', 'LR - GD', 'LR - SGD', 'LR - ADAM', 'LDA', 'QDA', 'KNN']\n",
    "    if dataset_name == 'adult':\n",
    "        results = pd.DataFrame([gd_metrics, sgd_metrics, adam_metrics, lda_metrics, qda_metrics, knn_metrics]) \n",
    "        index.pop(0)\n",
    "    else:\n",
    "        results = pd.DataFrame([irls_metrics, gd_metrics, sgd_metrics, adam_metrics, lda_metrics, qda_metrics, knn_metrics]) \n",
    "    results.index=index\n",
    "    results.columns=['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    results = results.transpose()\n",
    "    results.index.name=\"Metric\"\n",
    "\n",
    "    results.to_csv(f\"./../results/comparison_with_popular_{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4458e71",
   "metadata": {},
   "source": [
    "### 4. Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90670dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=0.9\n",
    "b2=0.999\n",
    "eps=1e-8\n",
    "sample_size = 1\n",
    "learning_rate = 1e-4 \n",
    "\n",
    "patience=50\n",
    "min_delta=1e-4 \n",
    "iterations = 1000  \n",
    "\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71cb7401",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "qda = QDA()\n",
    "knn = KNeighborsClassifier(n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38f3573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in subsets_lst:\n",
    "    \n",
    "    X_test_key, y_test_key, X_train_key, y_train_key = item\n",
    "    X_test, y_test, X_train, y_train = frames[X_test_key], frames[y_test_key], frames[X_train_key], frames[y_train_key]\n",
    "    X_train_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "    y_test = [y for row in y_test for y in row]\n",
    "\n",
    "    dataset_name=X_train_key.split(\"_\")[0]\n",
    "    \n",
    "    irls_kwds={\"iterations\": iterations, \"min_delta\":min_delta, \"patience\":patience}\n",
    "    gd_kwds={\"iterations\": iterations, \"alpha\": learning_rate, \"min_delta\":min_delta, \"patience\":patience}\n",
    "    sgd_kwds={\"iterations\": iterations, \"alpha\": learning_rate, \"sample_size\": sample_size,\n",
    "        \"min_delta\":min_delta,\"patience\":patience}\n",
    "    adam_kwds={\"iterations\": iterations, \"b1\": b1, \"b2\": b2, \"alpha\": learning_rate, \"epsilon\": eps,\n",
    "        \"min_delta\":min_delta, \"patience\":patience}\n",
    "    \n",
    "    if dataset_name != 'adult':\n",
    "        irls_params, _, _, _ = logreg.fit(X_train_b,y_train,**irls_kwds)\n",
    "        _, irls_pred = logreg.predict(X_test_b, irls_params)\n",
    "        irls_metrics = ClassificationEvaluator().calculate_all(y_test,irls_pred)\n",
    "\n",
    "    gd_params, _, _, _ = logreg.fit(X_train_b,y_train,**gd_kwds)\n",
    "    _, gd_pred = logreg.predict(X_test_b, gd_params)\n",
    "    gd_metrics = ClassificationEvaluator().calculate_all(y_test,gd_pred)\n",
    "\n",
    "    sgd_params, _, _, _ = logreg.fit(X_train_b,y_train,**sgd_kwds)\n",
    "    _, sgd_pred = logreg.predict(X_test_b, sgd_params)\n",
    "    sgd_metrics = ClassificationEvaluator().calculate_all(y_test,sgd_pred)\n",
    "\n",
    "    adam_params, _, _, _ = logreg.fit(X_train,y_train,**adam_kwds)\n",
    "    _, adam_pred = logreg.predict(X_test, adam_params[0], adam_params[1])\n",
    "    adam_metrics = ClassificationEvaluator().calculate_all(y_test,adam_pred)\n",
    "\n",
    "    lda.fit(X_train, y_train)\n",
    "    lda_pred = lda.predict(X_test)\n",
    "    lda_metrics = ClassificationEvaluator().calculate_all(y_test,lda_pred)\n",
    "\n",
    "    qda.fit(X_train, y_train)\n",
    "    qda_pred = qda.predict(X_test)\n",
    "    qda_metrics = ClassificationEvaluator().calculate_all(y_test,qda_pred)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_metrics = ClassificationEvaluator().calculate_all(y_test,knn_pred)\n",
    "\n",
    "    index=['LR - IRLS', 'LR - GD', 'LR - SGD', 'LR - ADAM', 'LDA', 'QDA', 'KNN']\n",
    "    if dataset_name == 'adult':\n",
    "        results = pd.DataFrame([gd_metrics, sgd_metrics, adam_metrics, lda_metrics, qda_metrics, knn_metrics]) \n",
    "        index.pop(0)\n",
    "    else:\n",
    "        results = pd.DataFrame([irls_metrics, gd_metrics, sgd_metrics, adam_metrics, lda_metrics, qda_metrics, knn_metrics]) \n",
    "    results.index=index\n",
    "    results.columns=['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    results = results.transpose()\n",
    "    results.index.name=\"Metric\"\n",
    "    display(results)\n",
    "\n",
    "    results.to_csv(f\"./../results/comparison_with_popular_early_stop_{dataset_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
